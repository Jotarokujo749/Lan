from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
from bs4 import BeautifulSoup

app = Flask(__name__)
CORS(app)

sources = {
    "Wikipedia": lambda mot: f"https://fr.wikipedia.org/wiki/{mot}",
    "Wiktionnaire": lambda mot: f"https://fr.wiktionary.org/wiki/{mot}",
    "CNRTL": lambda mot: f"https://www.cnrtl.fr/definition/{mot}",
    "Reverso": lambda mot: f"https://dictionnaire.reverso.net/francais-definition/{mot}",
    "Larousse": lambda mot: f"https://www.larousse.fr/dictionnaires/francais/{mot}",
    "Doctissimo": lambda mot: f"https://www.doctissimo.fr/html/dico/{mot}.htm",
    "Santé.fr": lambda mot: f"https://www.sante.fr/recherche?q={mot}",
    "MedlinePlus": lambda mot: f"https://medlineplus.gov/french/{mot}.html",
    "Futura Sciences": lambda mot: f"https://www.futura-sciences.com/sciences/definitions/{mot}-123/",
    "Universalis": lambda mot: f"https://www.universalis.fr/encyclopedie/{mot}/",
    "L'Internaute": lambda mot: f"https://www.linternaute.fr/dictionnaire/fr/definition/{mot}/",
    "France Culture": lambda mot: f"https://www.radiofrance.fr/franceculture/recherche?q={mot}",
    "Le Robert": lambda mot: f"https://dictionnaire.lerobert.com/definition/{mot}",
    "Toupie": lambda mot: f"https://www.toupie.org/Dictionnaire/{mot}.htm",
    "Définition.fr": lambda mot: f"https://www.definition.fr/{mot}",
    "Lexique.org": lambda mot: f"https://www.lexique.org/dictionnaire/{mot}.html",
    "Techno-science": lambda mot: f"https://www.techno-science.net/definition/{mot}.html",
    "e-santé": lambda mot: f"https://www.e-sante.fr/{mot}/guide",
    "Pharmacorama": lambda mot: f"https://www.pharmacorama.com/{mot}.php",
    "Vikidia": lambda mot: f"https://fr.vikidia.org/wiki/{mot}"
}

def get_clean_text(url):
    try:
        res = requests.get(url, timeout=5, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")
        for tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
            tag.decompose()
        paragraphs = soup.find_all("p")
        cleaned = []
        for p in paragraphs:
            txt = p.get_text(strip=True)
            if len(txt) > 50 and "cookie" not in txt.lower() and "javascript" not in txt.lower():
                cleaned.append(txt)
            if len(cleaned) >= 1:
                break
        return cleaned[0] if cleaned else None
    except:
        return None

@app.route("/fusion", methods=["POST"])
def fusion():
    data = request.get_json()
    mot = data.get("mot", "").lower()

    fragments = []
    for name, func in sources.items():
        url = func(mot)
        txt = get_clean_text(url)
        if txt:
            fragments.append(f"{name} : {txt}")

    if not fragments:
        return jsonify({"fusion": "Aucune information utile trouvée sur les sources."})

    fusion_text = ". ".join(fragments[:6]) + "."
    return jsonify({"fusion": fusion_text})

if __name__ == "__main__":
    app.run(port=5002)
